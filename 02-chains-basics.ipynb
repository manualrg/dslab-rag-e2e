{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f10199-9bb5-488b-99ad-f43a16f71205",
   "metadata": {},
   "source": [
    "# LCEL and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8ae065-59d9-473a-a3ad-cef76ff962cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\functools.py' for module 'functools': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 308: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\shlex.py' for module 'shlex': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 1482: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\parse.py' for module 'urllib.parse': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 2031: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\pydoc_data\\topics.py' for module 'pydoc_data.topics': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 3128: character maps to <undefined>\n",
      "Failed to read module file 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\re\\_casefix.py' for module 're._casefix': UnicodeDecodeError\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 62, in load_extension\n",
      "    return self._load_extension(module_str)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\core\\extensions.py\", line 77, in _load_extension\n",
      "    mod = import_module(module_str)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'autoreload'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 219, in update_sources\n",
      "    self.source_by_modname[new_modname] = f.read()\n",
      "                                          ^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 911: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f434c7-b90c-4d59-aa61-a7c19158dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_mistralai import  ChatMistralAI\n",
    "from src import utils, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d368b0",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f55ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_settings = conf.load(file=\"settings.yaml\")\n",
    "conf_settings\n",
    "\n",
    "LLM_WORKHORSE = conf_settings.llm_workhorse\n",
    "LLM_FLAGSHIP = conf_settings.llm_flagship\n",
    "EMBEDDINGS = conf_settings.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18ae9c",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766b9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce456f-9041-4190-9ff6-6b4df407e747",
   "metadata": {},
   "source": [
    "# What is a Langchain chain\n",
    "\n",
    "It is a composition element that allow to build an structured pipeline to perform IA Generative tasks, specially (but not only) for RAGs\n",
    "\n",
    "\n",
    "Langchain chains are built (in version 1.x or above) using LCEL (LangChain Expression Language)\n",
    "\n",
    "Its core principles are: composability, streaming, async, parallelism\n",
    "\n",
    "The main chains are abstractions layers for:\n",
    "* LLMs\n",
    "* Prompts\n",
    "* VectorStores (Retriever + Embedding)\n",
    "* Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2854e",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4148496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you tell me the distance from the Earth to the Moon?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_chat_hist = [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{question}\")  # variables syntax\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt.invoke(\"Can you tell me the distance from the Earth to the Moon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168e82ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me an interesting fact about {topic}\")\n",
    "\n",
    "prompt.format_prompt(topic=\"Devops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4278186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"topic\": \"Devops\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a24de53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(input={\"topic\": \"Devops\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca44a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasePromptTemplate.invoke() missing 1 required positional argument: 'input'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt.invoke(topic=\"Devops\")\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950198a",
   "metadata": {},
   "source": [
    "## FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebf267e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define examples\n",
    "examples = [  # input/output keys\n",
    "    {\"input\": \"Q: What is LangChain?\", \"output\": \"A: LangChain is a framework for building applications powered by large language models (LLMs).\"},\n",
    "    {\"input\": \"Q: What is LCEL?\", \"output\": \"A: LCEL (LangChain Expression Language) is a way to build chains using composable operators like | for clarity and power.\"},\n",
    "]\n",
    "\n",
    "# 2. Create an example prompt template: input/output keys\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# 3. Few-shot wrapper\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "# 4. Final prompt template (instructions + few-shots + new user question)\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a concise AI assistant. Answer clearly.\\\n",
    "     The answer style should be like the following examples:\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4a200b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Q: What is LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content='A: LangChain is a framework for building applications powered by large language models (LLMs).', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt.invoke(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d836514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Q: What is LangChain?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A: LangChain is a framework for building applications powered by large language models (LLMs).', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='Q: What is LCEL?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A: LCEL (LangChain Expression Language) is a way to build chains using composable operators like | for clarity and power.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(few_shot_prompt\n",
    "          .format_prompt() \n",
    "          .to_messages()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae6f6ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a concise AI assistant. Answer clearly.     The answer style should be like the following examples:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Q: What is LangChain?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A: LangChain is a framework for building applications powered by large language models (LLMs).', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='Q: What is LCEL?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A: LCEL (LangChain Expression Language) is a way to build chains using composable operators like | for clarity and power.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='What is langgraph?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt.invoke(\"What is langgraph?\").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ced147",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34196f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a DevOps joke for you:\n",
      "\n",
      "Why do DevOps engineers always carry a ladder?\n",
      "\n",
      "Because they‚Äôre always working on the deployment pipeline! üòÑ\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI  # native\n",
    "\n",
    "client_openai = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "response = client_openai.responses.create(\n",
    "    model=LLM_WORKHORSE,\n",
    "    input=\"Tell me a joke about devops\",\n",
    "    temperature=0.2,\n",
    "    max_output_tokens=128,\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc1df126-aaf0-4b2b-90b8-fa3e70bf56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the DevOps engineer go broke?\\n\\nBecause he kept losing containers! üö¢üòÑ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 14, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8lhswT4rQU2p4Y27XGOlRU8kUpXC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c56c6-943c-7de3-88a6-18ed58627563-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 19, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(  # Langchain wrapper\n",
    "    model=LLM_WORKHORSE,\n",
    "    # temperature=0.2,\n",
    "    max_tokens=128,\n",
    "    )\n",
    "\n",
    "# How to call the LLM in langchain?\n",
    "\n",
    "llm.invoke(\"Tell me a joke about devops\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43397ab5",
   "metadata": {},
   "source": [
    "## Calling a Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d9fcd",
   "metadata": {},
   "source": [
    "**invoke (synchronous single input)**\n",
    "\n",
    "* Runs the chain once, blocking until it finishes.\n",
    "* Input = single dict or string (depending on your chain).\n",
    "* Output = single result.\n",
    "\n",
    "‚úÖ Use when you just need one response and don‚Äôt care about concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0095ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools and abstractions to help developers build complex workflows that combine LLM calls with other components such as data sources, APIs, and external computation. LangChain facilitates tasks like prompt management, chaining multiple LLM calls, integrating with document loaders and vector databases, and managing conversation memory, making it easier to create applications like chatbots, question-answering systems, and other AI-driven tools.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 12, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8liOF3SYtpPezMXdT6xjiqX5gzS3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c56c7-106d-7df2-8d7b-fc505e3749f6-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 12, 'output_tokens': 100, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is LangChain?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcd302",
   "metadata": {},
   "source": [
    "**ainvoke (asynchronous single input)**\n",
    "\n",
    "* Async version of invoke.\n",
    "* Returns a coroutine ‚Üí you must await it (inside async def).\n",
    "* Non-blocking ‚Üí allows parallel I/O (important for web apps, APIs).\n",
    "\n",
    "‚úÖ Use when building async applications (FastAPI, Streamlit, etc.) or when you want multiple requests in parallel.\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    result = await llm.ainvoke({\"question\": \"What is LCEL?\"})\n",
    "    print(result)\n",
    "\n",
    "asyncio.run(main())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cce7bd",
   "metadata": {},
   "source": [
    "**batch (synchronous multiple inputs)**\n",
    "\n",
    "* Run the chain on a list of inputs (e.g., multiple questions).\n",
    "* Executes them one by one under the hood (but can be parallelized with config).\n",
    "* Returns a list of results in the same order.\n",
    "\n",
    "‚úÖ Use when you have a list of tasks and don‚Äôt need async."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c75bb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**LangChain** is an open-source framework designed to help developers build applications powered by large language models (LLMs). It provides tools and abstractions that simplify the integration of LLMs with other data sources and APIs, enabling the creation of more complex and functional language model applications.\\n\\n### Key Features of LangChain:\\n- **Prompt Management:** Helps design, manage, and optimize prompts sent to LLMs.\\n- **Chains:** Allows chaining together multiple calls to LLMs or other components to create complex workflows.\\n- **Memory:** Maintains conversational state or context over multiple interactions.\\n- **Data Augmentation:** Integrates LLM' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 12, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8liQHR0k8hf1BmpmQ2EsbudrQdhV', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None} id='lc_run--019c56c7-19c7-7620-922d-c527f0f7a0ab-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 12, 'output_tokens': 128, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='LCEL can refer to different things depending on the context, but without additional context, it commonly stands for:\\n\\n1. **Lifetime Cost of Electricity (LCEL)** ‚Äì a measure used in energy economics to estimate the total cost of generating electricity over the lifetime of a power plant or facility, usually expressed in terms of cost per kilowatt-hour (kWh). This includes capital costs, operation and maintenance, fuel, and decommissioning costs.\\n\\n2. It could also be an acronym for specific organizations, programs, or technical terms in various fields.\\n\\nIf you provide more context (such as the field or industry), I can give a more' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 12, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8liQRfub00WC2V0uEXFIBOrtpsSV', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None} id='lc_run--019c56c7-19c9-7330-bd23-214fb4d9c2e1-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 12, 'output_tokens': 128, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='A **vector database** is a specialized type of database designed to store, index, and query high-dimensional vector representations of data. These vectors typically arise from transforming raw data (like text, images, audio, or video) into a numerical format using techniques such as machine learning models, especially embeddings from deep learning.\\n\\n### Key Characteristics of Vector Databases:\\n\\n- **Storage of Vectors:** Instead of traditional structured data (like tables with rows and columns), vector databases store vectors‚Äîarrays of numbers representing the features or meaning of the original data.\\n\\n- **Similarity Search:** They enable fast similarity searches, usually through nearest neighbor search algorithms (e' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 13, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8liQzYcWCUuxji758GVh5ylKy7fD', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None} id='lc_run--019c56c7-19cb-7070-a512-d3b0ef7c1b17-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 13, 'output_tokens': 128, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is LangChain?\",\n",
    "    \"What is LCEL?\",\n",
    "    \"What is a vector database?\"\n",
    "]\n",
    "\n",
    "results = llm.batch(questions,\n",
    "                    config=RunnableConfig(max_concurrency=10),\n",
    "                    )\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d014e73",
   "metadata": {},
   "source": [
    "**There is also:**\n",
    "* abatch ‚Üí async version of batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501b088",
   "metadata": {},
   "source": [
    "**stream (synchronous streaming)** \n",
    "* Instead of waiting for the entire response, you get tokens/chunks as they arrive.\n",
    "* Great for CLI apps or cases where you want immediate output.\n",
    "\n",
    "\n",
    "```python\n",
    "# Streaming call\n",
    "for chunk in chain.stream({\"question\": \"Explain LangChain Expression Language in simple terms.\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "```\n",
    "\n",
    "Here, token by token results are returned as generated, and the application is blocked. It is usefull when developing a CLI\n",
    "\n",
    "** astream (asynchronous streaming) **\n",
    "* Same as stream, but async-friendly.\n",
    "* Perfect for web apps (FastAPI, Streamlit, etc.) where you want token-by-token output and not block the application.\n",
    "\n",
    "```python \n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async for chunk in chain.astream({\"question\": \"Give me a short poem about LCEL.\"}):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n---\\nDone!\")\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7652e9",
   "metadata": {},
   "source": [
    "| Method    | Input       | Output style              | Use case                   |\n",
    "| --------- | ----------- | ------------------------- | -------------------------- |\n",
    "| `invoke`  | 1 input     | 1 final result            | Simple calls               |\n",
    "| `ainvoke` | 1 input     | 1 final result            | Async apps                 |\n",
    "| `batch`   | many inputs | list of results           | Bulk jobs                  |\n",
    "| `abatch`  | many inputs | list of results           | Async bulk                 |\n",
    "| `stream`  | 1 input     | generator of chunks       | CLI / sync streaming       |\n",
    "| `astream` | 1 input     | async generator of chunks | Web apps / async streaming |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5babec",
   "metadata": {},
   "source": [
    "# Chaining:\n",
    "\n",
    "* Chaining means linking multiple components (prompt templates, LLMs, output parsers, retrievers, tools, etc.) together into a pipeline.\n",
    "* The pipe operator (|) is the heart of LCEL ‚Äî it lets you compose these components like LEGO blocks.\n",
    "* Each component is a Runnable (anything that can accept input and produce output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c03182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An interesting fact about the Roman Empire is that it had an extensive and sophisticated network of roads‚Äîover 250,000 miles at its peak! These roads were so well constructed that many of them are still in use today. The phrase \"All roads lead to Rome\" comes from this impressive infrastructure, which helped the Romans efficiently manage their vast empire, enabling rapid military movement, trade, and communication across Europe, North Africa, and the Middle East.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 15, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8liVr6fje0jhgJLc9xKTx5cArlce', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c56c7-2d64-78c2-b1d2-f30537a62da5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 90, 'total_tokens': 105, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me an interesting fact about {topic}\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_WORKHORSE,\n",
    "    temperature=0.2,\n",
    "    max_tokens=128,\n",
    "    )\n",
    "\n",
    "\n",
    "chat = prompt | llm \n",
    "\n",
    "chat.invoke(input=\"Roman Empire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f539997d-b85e-480a-88fa-78099fc77232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An interesting fact about the Roman Empire is that it had an extensive and sophisticated network of roads‚Äîover 250,000 miles at its peak! These roads were so well constructed that some are still in use today. The phrase \"All roads lead to Rome\" comes from this impressive infrastructure, which helped the Romans efficiently manage their vast empire by facilitating trade, military movement, and communication.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 15, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_75546bd1a7', 'id': 'chatcmpl-D8lidCcLT6JHQB11rItpHWkQz0EBy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c56c7-4d76-7282-ac59-2e2b91506f48-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 77, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(input={\"topic\": \"Roman Empire\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9deffefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2046c8d",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed42f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a DevOps joke for you:\\n\\nWhy do DevOps engineers prefer dark mode?\\n\\nBecause light attracts bugs! üêõüòÑ\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me a joke about devops\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ffa43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= \"\"\"\n",
    "A LA ATT. DE SEGUROS LLOYD:\n",
    "EN DON BENITO, A 08 MARZO 2014\n",
    "\n",
    "YO, CARMEN ESPA√ëOLA ESPA√ëOLA,\n",
    "CON DNI 99999999R, QUIERO DARME\n",
    "DE BAJA DEL SEGURO DE COCHE QUE\n",
    "TENGO CON USTEDES POR LA VENTA DEL\n",
    "MISMO.\n",
    "\n",
    "EL N√öMERO DE P√ìLIZA ES h2024038\n",
    "Y SE CORRESPONDE CON UN OPEL CORSA 1.2L\n",
    "CON MATR√çCULA 5473 BXM\n",
    "\n",
    "[signature]\n",
    "\n",
    "Dta. CARMEN ESPA√ëOLA\n",
    "ESPA√ëOLA\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e91f9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class DatosPoliza(BaseModel):\n",
    "    fecha: Optional[str] = Field(description=\"Si existe, la fecha a la que se firma la solicitud\")\n",
    "    dni:  Optional[str] = Field(description=\"Si existe, el DNI o n√∫mero de pasarporte del solicitante\")\n",
    "    nro_poliza:  Optional[str]  = Field(description=\"Si existe, el n√∫mero de p√≥liza sobre el que el solicitante desea realizar una acci√≥n\")\n",
    "    marca_model:  Optional[str] = Field(description=\"Si aparece, la marca y/o el modelo del veh√≠culo asociado a la p√≥liza\")\n",
    "    matricula:  Optional[str] = Field(description=\"Si aparece, la matr√≠cula veh√≠culo asociado a la p√≥liza\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e65a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model to output structured data using the Pydantic model\n",
    "llm_with_struct_outputs = llm.with_structured_output(DatosPoliza)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"Eres un analista que se dedica al cribado de solicitudes de seguros. Tu misi√≥n es leer detenidamente el correo de un asegurado y extraer informaci√≥n clave)\"},\n",
    "    {\"role\": \"human\", \"content\": \"Correo de solicitud {data}.\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68931d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a structured response by invoking the RunnableSequence\n",
    "response = llm_with_struct_outputs.invoke(\"What's the weather in Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1906e785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatosPoliza(fecha='08 MARZO 2014', dni='99999999R', nro_poliza='h2024038', marca_model='OPEL CORSA 1.2L', matricula='5473 BXM')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_policy_parsing = prompt | llm_with_struct_outputs\n",
    "\n",
    "chain_policy_parsing.invoke({\"data\": data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad0e1f",
   "metadata": {},
   "source": [
    "# Other components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3fd04",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "912fb34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embeddins!\n",
    "embeddings = OpenAIEmbeddings()\n",
    "q_vec = embeddings.embed_query(\"Tell me a joke about devops\")\n",
    "len(q_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcfb76",
   "metadata": {},
   "source": [
    "## VectorDB and Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43694078",
   "metadata": {},
   "source": [
    "### Create a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d960ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lst_collections)=0\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client_qdrant = QdrantClient(\":memory:\")\n",
    "\n",
    "try:\n",
    "    response= client_qdrant.get_collections()\n",
    "    lst_collections = response.collections\n",
    "    print(f\"{len(lst_collections)=}\")\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa861e",
   "metadata": {},
   "source": [
    "### Create an index (collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMB_DIM = len(q_vec)\n",
    "# #############################################\n",
    "if client_qdrant.collection_exists(\"tutorial\"):\n",
    "    client_qdrant.delete_collection(\"tutorial\")\n",
    "# #############################################\n",
    "\n",
    "client_qdrant.create_collection(\n",
    "    collection_name=\"tutorial\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=EMB_DIM,\n",
    "        distance=Distance.COSINE),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7b965",
   "metadata": {},
   "source": [
    "### Load docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31cc63c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2690cf82-ebfd-48bc-bd52-c61a595a212a',\n",
       " '0e8f454e-3ebf-434b-a7cf-26489695bcd0']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"John J. Hopfield and Geoffrey Hinton received the Nobel Prize in Physics in 2024 for their groundbreaking work on artificial neural networks, a foundation of modern AI. Hopfield developed an associative memory model in the 1980s that allows networks to store and reconstruct patterns. Building on this, Hinton developed the Boltzmann machine, which uses statistical physics principles to recognize and classify data. These pioneering contributions are essential for today's machine learning technologies, enhancing applications from medical imaging to material science.\",\n",
    "        metadata={\"source\": \"wikipedia\", \"topic\": \"Physics\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"In Chemistry, David Baker, Demis Hassabis, and John Jumper were honored win Nobel Prize in 2024 for their breakthroughs in protein structure prediction. Baker‚Äôs work in computational protein design enables the creation of novel proteins, while Hassabis and Jumper, known for their work with DeepMind's AlphaFold, developed an AI that accurately predicts protein structures‚Äîa long-standing challenge in biology. This advancement could lead to transformative applications in drug development and synthetic biology.\",\n",
    "        metadata={\"source\": \"wikipedia\", \"topic\": \"Chemistry\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# This example is wrong: https://qdrant.tech/documentation/frameworks/langchain/#using-an-existing-collection\n",
    "# Use embedding instead of embeddings, like in Langchain documentation:\n",
    "# https://python.langchain.com/api_reference/_modules/langchain_qdrant/qdrant.html#QdrantVectorStore.from_existing_collection\n",
    "\n",
    "# from memory:\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client_qdrant,\n",
    "    collection_name=\"tutorial\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "# uuids = [str(uuid.uuid4()) for _ in range(len(docs))]\n",
    "\n",
    "uuids = [\n",
    "    '2690cf82-ebfd-48bc-bd52-c61a595a212a',\n",
    "    '0e8f454e-3ebf-434b-a7cf-26489695bcd0'\n",
    "    ]\n",
    "\n",
    "\n",
    "vector_store.add_documents(documents=docs, ids=uuids)  # Add only once!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69cd742",
   "metadata": {},
   "source": [
    "### Query the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fb6ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'wikipedia', 'topic': 'Physics', '_id': '2690cf82-ebfd-48bc-bd52-c61a595a212a', '_collection_name': 'tutorial'}, page_content=\"John J. Hopfield and Geoffrey Hinton received the Nobel Prize in Physics in 2024 for their groundbreaking work on artificial neural networks, a foundation of modern AI. Hopfield developed an associative memory model in the 1980s that allows networks to store and reconstruct patterns. Building on this, Hinton developed the Boltzmann machine, which uses statistical physics principles to recognize and classify data. These pioneering contributions are essential for today's machine learning technologies, enhancing applications from medical imaging to material science.\"),\n",
       " Document(metadata={'source': 'wikipedia', 'topic': 'Chemistry', '_id': '0e8f454e-3ebf-434b-a7cf-26489695bcd0', '_collection_name': 'tutorial'}, page_content=\"In Chemistry, David Baker, Demis Hassabis, and John Jumper were honored win Nobel Prize in 2024 for their breakthroughs in protein structure prediction. Baker‚Äôs work in computational protein design enables the creation of novel proteins, while Hassabis and Jumper, known for their work with DeepMind's AlphaFold, developed an AI that accurately predicts protein structures‚Äîa long-standing challenge in biology. This advancement could lead to transformative applications in drug development and synthetic biology.\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"Who is Geoffrey Hinton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a97bc8",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "A langchain vector_store is not a `chain` object and does not have a `.invoke()` method\n",
    "We need to cast it to `retriever` that is the abstraction layer over the vector_store \n",
    "to query documents (contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf4054ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'wikipedia', 'topic': 'Chemistry', '_id': '0e8f454e-3ebf-434b-a7cf-26489695bcd0', '_collection_name': 'tutorial'}, page_content=\"In Chemistry, David Baker, Demis Hassabis, and John Jumper were honored win Nobel Prize in 2024 for their breakthroughs in protein structure prediction. Baker‚Äôs work in computational protein design enables the creation of novel proteins, while Hassabis and Jumper, known for their work with DeepMind's AlphaFold, developed an AI that accurately predicts protein structures‚Äîa long-standing challenge in biology. This advancement could lead to transformative applications in drug development and synthetic biology.\"),\n",
       " Document(metadata={'source': 'wikipedia', 'topic': 'Physics', '_id': '2690cf82-ebfd-48bc-bd52-c61a595a212a', '_collection_name': 'tutorial'}, page_content=\"John J. Hopfield and Geoffrey Hinton received the Nobel Prize in Physics in 2024 for their groundbreaking work on artificial neural networks, a foundation of modern AI. Hopfield developed an associative memory model in the 1980s that allows networks to store and reconstruct patterns. Building on this, Hinton developed the Boltzmann machine, which uses statistical physics principles to recognize and classify data. These pioneering contributions are essential for today's machine learning technologies, enhancing applications from medical imaging to material science.\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(k=1)\n",
    "\n",
    "retriever.invoke(\"Nobel Price Physics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b335c",
   "metadata": {},
   "source": [
    "## Doc Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b0cf2",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "\n",
    "FILE_PATH = [(path_input / \"Divulgacion-Planetaria-Althera.pdf\").as_posix()]  # for multiple files\n",
    "EXPORT_TYPE = ExportType.MARKDOWN   # ExportType.DOC_CHUNKS\n",
    "TOKENIZER_NAME =\"cl100k_base\"\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    ")\n",
    "\n",
    "lst_docs = loader.load()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81422313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Un nuevo y fascinante vecino: Alth√©ra\n",
       "\n",
       "# √çndice\n",
       "\n",
       "1. Historia del descubrimiento\n",
       "2. Conoce a Alth√©ra\n",
       "3. Los soles de Alth√©ra\n",
       "4. Estructura general de Alth√©ra\n",
       "5. Planetas interiores\n",
       "6. Planetas exteriores\n",
       "7. Lunas y sat√©lites menores\n",
       "8. Fen√≥menos destacados\n",
       "9. Habitabilidad y astrobiolog√≠a\n",
       "10. Conclusiones y perspectivas futuras\n",
       "\n",
       "# 1. Historia del descubrimiento\n",
       "\n",
       "## 1.1 Primeras observaciones y sospechas iniciales\n",
       "\n",
       "El sistema binario Alth√©ra ( HD 4579 AB ) fue detectado por primera vez en el a√±o 2032 durante una campa√±a de observaci√≥n del Observatorio Espacial James Webb , dirigida por la astrof√≠sica chilena Dra. Mariela Estay . La misi√≥n principal era estudiar la composici√≥n atmosf√©rica de exoplanetas candidatos a la habitabilidad, pero un patr√≥n an√≥malo en el flujo luminoso proveniente de la constelaci√≥n de Ori√≥n llam√≥ la atenci√≥n del equipo. El an√°lisis de curvas de luz revel√≥ oscilaciones peri√≥dicas dobles, un indicio claro de la presencia de dos estrellas en √≥rbita mutua y varios "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def read_md(path, encoding=\"utf-8\"):\n",
    "    with open(path, \"r\", encoding=encoding) as f:\n",
    "        doc_md = f.read()\n",
    "    return doc_md\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "doc_md = read_md(\"data/interim/Divulgacion-Planetaria-Althera.md\")\n",
    "\n",
    "Markdown(doc_md[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0a13e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [Document(\n",
    "    page_content=doc_md,\n",
    "    metadata={\n",
    "        \"source\": \"Divulgacion-Planetaria-Althera.md\"\n",
    "    }\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fde6c",
   "metadata": {},
   "source": [
    "### Text Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c7ee559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "TOKENIZER_NAME =\"cl100k_base\"\n",
    "\n",
    "text_splitter_rcs = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=TOKENIZER_NAME,\n",
    "    chunk_size=256,  # from_tiktoken_encoder: tokens\n",
    "    chunk_overlap=25  # tokens\n",
    ")\n",
    "corpus_rcs = text_splitter_rcs.split_documents(corpus)  # corpus is a list of LG Documents\n",
    "len(corpus_rcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af719a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Un nuevo y fascinante vecino: Alth√©ra\n",
       "\n",
       "# √çndice\n",
       "\n",
       "1. Historia del descubrimiento\n",
       "2. Conoce a Alth√©ra\n",
       "3. Los soles de Alth√©ra\n",
       "4. Estructura general de Alth√©ra\n",
       "5. Planetas interiores\n",
       "6. Planetas exteriores\n",
       "7. Lunas y sat√©lites menores\n",
       "8. Fen√≥menos destacados\n",
       "9. Habitabilidad y astrobiolog√≠a\n",
       "10. Conclusiones y perspectivas futuras\n",
       "\n",
       "# 1. Historia del descubrimiento\n",
       "\n",
       "## 1.1 Primeras observaciones y sospechas iniciales"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Markdown(corpus_rcs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49b53e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1.1 Primeras observaciones y sospechas iniciales\n",
       "\n",
       "El sistema binario Alth√©ra ( HD 4579 AB ) fue detectado por primera vez en el a√±o 2032 durante una campa√±a de observaci√≥n del Observatorio Espacial James Webb , dirigida por la astrof√≠sica chilena Dra. Mariela Estay . La misi√≥n principal era estudiar la composici√≥n atmosf√©rica de exoplanetas candidatos a la habitabilidad, pero un patr√≥n an√≥malo en el flujo luminoso proveniente de la constelaci√≥n de Ori√≥n llam√≥ la atenci√≥n del equipo. El an√°lisis de curvas de luz revel√≥ oscilaciones peri√≥dicas dobles, un indicio claro de la presencia de dos estrellas en √≥rbita mutua y varios cuerpos orbitando de forma circumbinaria.\n",
       "\n",
       "## 1.2 Confirmaci√≥n mediante t√©cnicas combinadas\n",
       "\n",
       "En los meses siguientes, un consorcio internacional liderado por la Agencia Espacial Europea (ESA) y el Instituto Max Planck de Astronom√≠a despleg√≥ observaciones complementarias utilizando:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(corpus_rcs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb81d5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- ELT (Extremely Large Telescope) en el Desierto de Atacama para espectroscop√≠a de alta resoluci√≥n.\n",
       "- Telescopio Espacial Nancy Grace Roman para fotometr√≠a de gran precisi√≥n en tr√°nsitos.\n",
       "- Interferometr√≠a de radio desde la red Very Long Baseline Array (VLBA) para afinar la distancia y par√°metros orbitales del sistema.\n",
       "\n",
       "Fue el equipo del astr√≥nomo estadounidense Dr. Jonathan Kepler-Saunders quien confirm√≥, mediante el m√©todo de velocidad radial ultraestable, la existencia de cinco planetas principales y varios cinturones de escombros.\n",
       "\n",
       "## 1.3 Descubrimiento revolucionario de la zona habitable circumbinaria"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(corpus_rcs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b7fb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    # (\"##\", \"Header 2\"),\n",
    "\n",
    "]\n",
    "\n",
    "text_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on,\n",
    "    strip_headers =False\n",
    "    )\n",
    "corpus_mds = text_splitter.split_text(doc_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e2f0f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Un nuevo y fascinante vecino: Alth√©ra"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(corpus_mds[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a298c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# √çndice  \n",
       "1. Historia del descubrimiento\n",
       "2. Conoce a Alth√©ra\n",
       "3. Los soles de Alth√©ra\n",
       "4. Estructura general de Alth√©ra\n",
       "5. Planetas interiores\n",
       "6. Planetas exteriores\n",
       "7. Lunas y sat√©lites menores\n",
       "8. Fen√≥menos destacados\n",
       "9. Habitabilidad y astrobiolog√≠a\n",
       "10. Conclusiones y perspectivas futuras"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(corpus_mds[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c75f7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# 1. Historia del descubrimiento  \n",
       "## 1.1 Primeras observaciones y sospechas iniciales  \n",
       "El sistema binario Alth√©ra ( HD 4579 AB ) fue detectado por primera vez en el a√±o 2032 durante una campa√±a de observaci√≥n del Observatorio Espacial James Webb , dirigida por la astrof√≠sica chilena Dra. Mariela Estay . La misi√≥n principal era estudiar la composici√≥n atmosf√©rica de exoplanetas candidatos a la habitabilidad, pero un patr√≥n an√≥malo en el flujo luminoso proveniente de la constelaci√≥n de Ori√≥n llam√≥ la atenci√≥n del equipo. El an√°lisis de curvas de luz revel√≥ oscilaciones peri√≥dicas dobles, un indicio claro de la presencia de dos estrellas en √≥rbita mutua y varios cuerpos orbitando de forma circumbinaria.  \n",
       "## 1.2 Confirmaci√≥n mediante t√©cnicas combinadas  \n",
       "En los meses siguientes, un consorcio internacional liderado por la Agencia Espacial Europea (ESA) y el Instituto Max Planck de Astronom√≠a despleg√≥ observaciones complementarias utilizando:  \n",
       "- ELT (Extremely Large Telescope) en el Desierto de Atacama para espectroscop√≠a de alta resoluci√≥n.\n",
       "- Telescopio Espacial Nancy Grace Roman para fotometr√≠a de gran precisi√≥n en tr√°nsitos.\n",
       "- Interferometr√≠a de radio desde la red Very Long Baseline Array (VLBA) para afinar la distancia y par√°metros orbitales del sistema.  \n",
       "Fue el equipo del astr√≥nomo estadounidense Dr. Jonathan Kepler-Saunders quien confirm√≥, mediante el m√©todo de velocidad radial ultraestable, la existencia de cinco planetas principales y varios cinturones de escombros.  \n",
       "## 1.3 Descubrimiento revolucionario de la zona habitable circumbinaria  \n",
       "El hallazgo m√°s impactante lleg√≥ en 2034, cuando la misi√≥n LUVOIR-B (Large UV/Optical/IR Surveyor) detect√≥ la firma espectral de vapor de agua, ox√≠geno molecular y metano en la atm√≥sfera de Aurelia III , un planeta ubicado en la zona habitable del sistema, orbitando a ambos soles. Este fue el primer caso documentado de un mundo potencialmente habitable en un sistema binario cercano -a tan solo 42,7 a√±os luz de la Tierra -, lo que lo convierte en un candidato ideal para futuras misiones de exploraci√≥n interestelar.  \n",
       "## 1.4 Importancia cient√≠fica y proyecci√≥n futura  \n",
       "El descubrimiento de Alth√©ra revolucion√≥ la astrobiolog√≠a y la f√≠sica orbital por tres razones clave:  \n",
       "1. Din√°mica circumbinaria estable - demostr√≥ que los planetas pueden mantener √≥rbitas estables y climas equilibrados alrededor de dos soles, desafiando modelos anteriores.\n",
       "2. Qu√≠mica atmosf√©rica compleja - Aurelia III presenta una mezcla de gases que, en equilibrio fotoqu√≠mico, sugieren procesos biol√≥gicos o geoqu√≠micos activos.\n",
       "3. Proximidad relativa - su cercan√≠a permite observaciones directas en la pr√≥xima d√©cada con telescopios como el Habitable Worlds Observatory (HWO) y misiones de espectrometr√≠a directa de superficie como Starshot Spectra .  \n",
       "En 2036, la Uni√≥n Astron√≥mica Internacional otorg√≥ a este hallazgo el Premio Messier de Descubrimiento Astron√≥mico y estableci√≥ el Programa Alth√©ra , un plan coordinado de investigaci√≥n que combina observaciones remotas, simulaciones clim√°ticas y dise√±o de futuras sondas interestelares."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(corpus_mds[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70503d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
