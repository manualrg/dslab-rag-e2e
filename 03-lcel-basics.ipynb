{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f10199-9bb5-488b-99ad-f43a16f71205",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8ae065-59d9-473a-a3ad-cef76ff962cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f434c7-b90c-4d59-aa61-a7c19158dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from src import utils, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ce2bd",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b66b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa7cf2",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a3e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_settings = conf.load(file=\"settings.yaml\")\n",
    "conf_settings\n",
    "\n",
    "LLM_WORKHORSE = conf_settings.llm_workhorse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f61b2-8ac5-4579-b4c8-403506aac3cc",
   "metadata": {},
   "source": [
    "A chain is an instance of the Runnable inteface and each step of a chain is also an instance of the Runnable interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4ef08-3436-4750-b87a-08b3e2075697",
   "metadata": {},
   "source": [
    "# The Runnable Interface\n",
    "\n",
    "A chain is an instance of the Runnable Interface. In addition, every step of a chain is an instance of the Runnable Interface\n",
    "\n",
    "An instance of a Runnable Interface can be chained with other with the overloaded operator `|`\n",
    "\n",
    "`An interface is a design template for creating classes that share common methods. The methods defined in an interface are abstract, meaning they are only outlined and lack implementation. They act as blueprints for concrete implementations`\n",
    "\n",
    "\n",
    "*In LangChain everything that can be part of a chain implements the Runnable interface.\n",
    "* A Runnable is an abstraction:\n",
    ">“An object that takes some input, does something with it, and produces some output.”\n",
    "* This makes prompts, LLMs, retrievers, parsers, custom functions… all first-class citizens that you can compose.\n",
    "\n",
    "Rules of a Runnable: Must implement a common set of methods (sync + async + batch + streaming):\n",
    "\n",
    "| Method              | Purpose                          |\n",
    "| ------------------- | -------------------------------- |\n",
    "| `.invoke(input)`    | Run on a single input (sync).    |\n",
    "| `.ainvoke(input)`   | Run on a single input (async).   |\n",
    "| `.batch([inputs])`  | Run on a list of inputs (sync).  |\n",
    "| `.abatch([inputs])` | Run on a list of inputs (async). |\n",
    "| `.stream(input)`    | Stream output chunks (sync).     |\n",
    "| `.astream(input)`   | Stream output chunks (async).    |\n",
    "\n",
    "\n",
    "Kinds of Runnables related to LLM chains:\n",
    "* prompts\n",
    "* LLMs\n",
    "* retrievers\n",
    "* Output parsers\n",
    "\n",
    "\n",
    "\n",
    "https://python.langchain.com/docs/concepts/runnables/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a774bdb",
   "metadata": {},
   "source": [
    "## RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "* RunnablePassthrough: It is a placeholder\n",
    "* RunnableLambda: Applies a f unction\n",
    "* RunnableParallel: Runs multiple Runnables in a parallel flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a348812-a736-4edb-947d-1f75a97647e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff4d39e-f93d-4f98-be3e-4a322665cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_to_upper(input: str):\n",
    "    output = input.upper()\n",
    "    return output\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad7f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RunnablePassthrough() \n",
    " | RunnableLambda(input_to_upper) \n",
    " | RunnablePassthrough()\n",
    " ).invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3785ded7-b7d8-4ed8-8456-3e33676e62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\"x\": RunnablePassthrough(),  # branch x\n",
    "     \"y\": RunnablePassthrough()  # branch y\n",
    "     }\n",
    ")\n",
    "    \n",
    "\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e40e93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'HELLO', 'b': 'hello'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\"a\": RunnableLambda(input_to_upper) ,  # branch 1\n",
    "     \"b\": RunnableLambda(lambda x:  x.lower())   # branch 2\n",
    "     }\n",
    ")\n",
    "    \n",
    "\n",
    "chain.invoke(\"HeLLo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61d756",
   "metadata": {},
   "source": [
    "## Input methods\n",
    "\n",
    "A Runnable can take any input data that makes sense with the `invoke` implementation.\n",
    "\n",
    "In general strings and dictionaries are used\n",
    "\n",
    "Data is passed by: `input` argument or by kwargs to other Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c4a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me an interesting fact about {topic}\")\n",
    "\n",
    "prompt.invoke(\"Devops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d7414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"topic\": \"Devops\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c85e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Input to ChatPromptTemplate is missing variables {'topic'}.  Expected: ['topic'] Received: ['input']\\nNote: if you intended {topic} to be part of the string and not a variable, please escape it with double curly braces like: '{{topic}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt.invoke({\"input\": \"Devops\"})\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "826fe1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = RunnableLambda(lambda x: x['key'])\n",
    "selector.invoke({\"key\": \"a\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dc44305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError('key')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    selector.invoke({\"some_key\": \"a\"})\n",
    "except Exception as err:\n",
    "    print(str(err.__repr__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77f5e571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'y': 2, 'z': {'a': 1, 'b': 2}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_a = RunnableLambda(lambda x: x['a'])\n",
    "branch_b = RunnableLambda(lambda x: x['b'])\n",
    "\n",
    "chain = RunnableParallel({\n",
    "    \"x\": branch_a,\n",
    "    \"y\": branch_b,\n",
    "    \"z\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "\n",
    "chain.invoke({\"a\": 1, \"b\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b43f6a",
   "metadata": {},
   "source": [
    "# RAG Simulation\n",
    "\n",
    "Prompt (Runnable) → LLM (Runnable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c3e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 1, 'query': 'a'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_retriever(query):\n",
    "    # doc_id -> doc_content\n",
    "    return {\"a\": 1, \"b\": 2, \"c\": 3}[query]\n",
    "\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),  # retrieved context\n",
    "     \"query\": RunnablePassthrough()  # keep the query\n",
    "     }\n",
    ")\n",
    "\n",
    "chain.invoke(\"a\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d414438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 1, 'query': 'a'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = RunnablePassthrough()\n",
    "\n",
    "\n",
    "chain_retrieval = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     }\n",
    ")\n",
    "\n",
    "chain = prompt | chain_retrieval\n",
    "\n",
    "chain.invoke(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc646f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'LangChain Expression Language (LCEL) is a declarative, pipe-based syntax (|) used to compose complex LLM apps',\n",
       " 'query': 'what is LCEL'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_retriever(query):\n",
    "    # doc_id -> doc_content\n",
    "    contexts = {\n",
    "        \"what is lcel\": \"LangChain Expression Language (LCEL) is a declarative, pipe-based syntax (|) used to compose complex LLM apps\",\n",
    "        \"what is langchain\": \"LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs)\",\n",
    "        \"what is langgraph\": \"LangGraph is an open-source framework and Python library developed by LangChain designed to build, manage, and deploy complex, stateful, and agent-based AI workflows\"}\n",
    "    return contexts[query.lower()]\n",
    "\n",
    "prompt = RunnablePassthrough()\n",
    "\n",
    "\n",
    "chain_retrieval = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     }\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | chain_retrieval\n",
    "\n",
    "chain.invoke(\"what is LCEL\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0db44c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'LangChain Expression Language (LCEL) is a declarative, pipe-based syntax (|) used to compose complex LLM apps',\n",
       " 'query': 'what is LCEL'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative syntax\n",
    "\n",
    "chain = (RunnablePassthrough()   # prompt\n",
    "         | {\"context\": RunnableLambda(fn_retriever),  # retrieved context\n",
    "            \"query\": RunnablePassthrough()  # keep the query (prompt)\n",
    "            } \n",
    ")\n",
    "\n",
    "chain.invoke(\"what is LCEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11add3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError(\"'dict' object has no attribute 'lower'\")\n"
     ]
    }
   ],
   "source": [
    "chain = (RunnablePassthrough() \n",
    "         | {\"context\": RunnableLambda(fn_retriever),\n",
    "            \"query\": RunnablePassthrough()\n",
    "            } \n",
    ")\n",
    "\n",
    "try:\n",
    "    chain.invoke(input={\"query\": \"what is LCEL\", \"other\": \"b\"})  # fn_retriever recieves a {} instead a query\n",
    "except Exception as err:\n",
    "    print(err.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56401d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'LangChain Expression Language (LCEL) is a declarative, pipe-based syntax (|) used to compose complex LLM apps', 'query': {'query': 'what is LCEL', 'other': 'b'}}\n"
     ]
    }
   ],
   "source": [
    "chain = (RunnablePassthrough() \n",
    "         | {\"context\": RunnableLambda(lambda x: x['query']) | RunnableLambda(fn_retriever),\n",
    "            \"query\": RunnablePassthrough()\n",
    "            } \n",
    ")\n",
    "\n",
    "try:\n",
    "    _ = chain.invoke(input={\"query\": \"what is LCEL\", \"other\": \"b\"})  # get the proper key and then pass to `fn_retriever`\n",
    "    print(_)\n",
    "except Exception as err:\n",
    "    print(err.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2bddc",
   "metadata": {},
   "source": [
    "# Assign method\n",
    "\n",
    "`.assign()` is a method available on any Runnable (including RunnablePassthrough).\n",
    "\n",
    "It creates a new chain that:\n",
    "\n",
    "* Takes the original input.\n",
    "* Runs one or more sub-Runnables or functions.\n",
    "* Adds their outputs as new keys in the input dictionary.\n",
    "* The original input is preserved.\n",
    "\n",
    "In short: it enriches the input with extra fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e545e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is LCEL?', 'question_length': 13}\n"
     ]
    }
   ],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    question_length=lambda x: len(x[\"question\"])\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"question\": \"What is LCEL?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb0812ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is LCEL', 'context': 'LangChain Expression Language (LCEL) is a declarative, pipe-based syntax (|) used to compose complex LLM apps'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = RunnablePassthrough()\n",
    "\n",
    "chain = prompt.assign(\n",
    "    context=lambda x: fn_retriever(x[\"question\"])\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"question\": \"What is LCEL\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741d194-03f1-4f48-8c2f-6b4bf83a65fd",
   "metadata": {},
   "source": [
    "# Anex: Implement your own Runnable Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae864ccf-b9d0-4dc3-a0ed-f2554b5f8939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen:  10\n",
      "Multiply by 2:  20\n",
      "Convert to string:  40\n",
      "Result: 40\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class CRunnable(ABC):\n",
    "    def __init__(self):\n",
    "        self.next = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def process(self, data):\n",
    "        \"\"\"\n",
    "        This method must be implemented by subclasses to define\n",
    "        data processing behavior.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next is not None:\n",
    "            return self.next.invoke(processed_data)\n",
    "        return processed_data\n",
    "\n",
    "    def __or__(self, other):\n",
    "        return CRunnableSequence(self, other)\n",
    "\n",
    "\n",
    "\n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def process(self, data):\n",
    "        return data\n",
    "\n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)\n",
    "\n",
    "class AddTen(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"AddTen: \", data)\n",
    "        return data + 10\n",
    "\n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Multiply by 2: \", data)\n",
    "        return data * 2\n",
    "\n",
    "class ConvertToString(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Convert to string: \", data)\n",
    "        return f\"Result: {data}\"\n",
    "\n",
    "\n",
    "a = AddTen()\n",
    "b = MultiplyByTwo()\n",
    "c = ConvertToString()\n",
    "\n",
    "chain = a | b | c\n",
    "\n",
    "result = chain.invoke(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f3222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
