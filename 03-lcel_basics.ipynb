{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f10199-9bb5-488b-99ad-f43a16f71205",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8ae065-59d9-473a-a3ad-cef76ff962cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f434c7-b90c-4d59-aa61-a7c19158dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src import utils, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ce2bd",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b66b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa7cf2",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a3e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_settings = conf.load(file=\"settings.yaml\")\n",
    "conf_settings\n",
    "\n",
    "LLM_WORKHORSE = \"gpt-4.1-mini-2025-04-14\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f61b2-8ac5-4579-b4c8-403506aac3cc",
   "metadata": {},
   "source": [
    "A chain is an instance of the Runnable inteface and each step of a chain is also an instance of the Runnable interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4ef08-3436-4750-b87a-08b3e2075697",
   "metadata": {},
   "source": [
    "# The Runnable Interface\n",
    "\n",
    "A chain is an instance of the Runnable Interface. In addition, every step of a chain is an instance of the Runnable Interface\n",
    "\n",
    "An instance of a Runnable Interface can be chained with other with the overloaded operator `|`\n",
    "\n",
    "`An interface is a design template for creating classes that share common methods. The methods defined in an interface are abstract, meaning they are only outlined and lack implementation. They act as blueprints for concrete implementations`\n",
    "\n",
    "\n",
    "*In LangChain everything that can be part of a chain implements the Runnable interface.\n",
    "* A Runnable is an abstraction:\n",
    ">“An object that takes some input, does something with it, and produces some output.”\n",
    "* This makes prompts, LLMs, retrievers, parsers, custom functions… all first-class citizens that you can compose.\n",
    "\n",
    "Rules of a Runnable: Must implement a common set of methods (sync + async + batch + streaming):\n",
    "\n",
    "| Method              | Purpose                          |\n",
    "| ------------------- | -------------------------------- |\n",
    "| `.invoke(input)`    | Run on a single input (sync).    |\n",
    "| `.ainvoke(input)`   | Run on a single input (async).   |\n",
    "| `.batch([inputs])`  | Run on a list of inputs (sync).  |\n",
    "| `.abatch([inputs])` | Run on a list of inputs (async). |\n",
    "| `.stream(input)`    | Stream output chunks (sync).     |\n",
    "| `.astream(input)`   | Stream output chunks (async).    |\n",
    "\n",
    "\n",
    "Kinds of Runnables related to LLM chains:\n",
    "* prompts\n",
    "* LLMs\n",
    "* retrievers\n",
    "* Output parsers\n",
    "\n",
    "\n",
    "\n",
    "https://python.langchain.com/docs/concepts/runnables/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a774bdb",
   "metadata": {},
   "source": [
    "## RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "* RunnablePassthrough: It is a placeholder\n",
    "* RunnableLambda: Applies a f unction\n",
    "* RunnableParallel: Runs multiple Runnables in a parallel flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a348812-a736-4edb-947d-1f75a97647e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff4d39e-f93d-4f98-be3e-4a322665cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_to_upper(input: str):\n",
    "    output = input.upper()\n",
    "    return output\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3785ded7-b7d8-4ed8-8456-3e33676e62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\"x\": RunnablePassthrough(),  # branch 1\n",
    "     \"y\": RunnablePassthrough()  # branch 2\n",
    "     }\n",
    ")\n",
    "    \n",
    "\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61d756",
   "metadata": {},
   "source": [
    "## Input methods\n",
    "\n",
    "A Runnable can take any input data that makes sense with the `invoke` implementation.\n",
    "\n",
    "In general strings and dictionaries are used\n",
    "\n",
    "Data is passed by: `input` argument or by kwargs to other Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c4a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me an interesting fact about {topic}\")\n",
    "\n",
    "prompt.invoke(\"Devops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d7414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me an interesting fact about Devops', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"topic\": \"Devops\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c85e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Input to ChatPromptTemplate is missing variables {'topic'}.  Expected: ['topic'] Received: ['input']\\nNote: if you intended {topic} to be part of the string and not a variable, please escape it with double curly braces like: '{{topic}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt.invoke({\"input\": \"Devops\"})\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b43f6a",
   "metadata": {},
   "source": [
    "## RAG Simulation\n",
    "\n",
    "Prompt (Runnable) → LLM (Runnable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595c3e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 1, 'query': 'a'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_retriever(query):\n",
    "    return {\"a\": 1, \"b\": 2, \"c\": 3}[query]\n",
    "\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     }\n",
    ")\n",
    "\n",
    "chain.invoke(\"a\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d414438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 1, 'query': 'a'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = RunnablePassthrough()\n",
    "\n",
    "\n",
    "retri = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     }\n",
    ")\n",
    "\n",
    "chain = prompt | retri\n",
    "\n",
    "chain.invoke(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0db44c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 1, 'query': 'a'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative syntax\n",
    "\n",
    "prompt = RunnablePassthrough()\n",
    "\n",
    "retri = RunnableParallel(\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     }\n",
    ")\n",
    "\n",
    "chain = (prompt |\n",
    "    {\"context\": RunnableLambda(fn_retriever),\n",
    "     \"query\": RunnablePassthrough()\n",
    "     } \n",
    ")\n",
    "\n",
    "chain.invoke(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2bddc",
   "metadata": {},
   "source": [
    "## Assign function\n",
    "\n",
    "`.assign()` is a method available on any Runnable (including RunnablePassthrough).\n",
    "\n",
    "It creates a new chain that:\n",
    "\n",
    "* Takes the original input.\n",
    "* Runs one or more sub-Runnables or functions.\n",
    "* Adds their outputs as new keys in the input dictionary.\n",
    "* The original input is preserved.\n",
    "\n",
    "In short: it enriches the input with extra fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e545e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is LCEL?', 'question_length': 13}\n"
     ]
    }
   ],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    question_length=lambda x: len(x[\"question\"])\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"question\": \"What is LCEL?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741d194-03f1-4f48-8c2f-6b4bf83a65fd",
   "metadata": {},
   "source": [
    "# Implement your own Runnable Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae864ccf-b9d0-4dc3-a0ed-f2554b5f8939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen:  10\n",
      "Multiply by 2:  20\n",
      "Convert to string:  40\n",
      "Result: 40\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class CRunnable(ABC):\n",
    "    def __init__(self):\n",
    "        self.next = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def process(self, data):\n",
    "        \"\"\"\n",
    "        This method must be implemented by subclasses to define\n",
    "        data processing behavior.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next is not None:\n",
    "            return self.next.invoke(processed_data)\n",
    "        return processed_data\n",
    "\n",
    "    def __or__(self, other):\n",
    "        return CRunnableSequence(self, other)\n",
    "\n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def process(self, data):\n",
    "        return data\n",
    "\n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)\n",
    "\n",
    "class AddTen(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"AddTen: \", data)\n",
    "        return data + 10\n",
    "\n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Multiply by 2: \", data)\n",
    "        return data * 2\n",
    "\n",
    "class ConvertToString(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Convert to string: \", data)\n",
    "        return f\"Result: {data}\"\n",
    "\n",
    "\n",
    "a = AddTen()\n",
    "b = MultiplyByTwo()\n",
    "c = ConvertToString()\n",
    "\n",
    "chain = a | b | c\n",
    "\n",
    "result = chain.invoke(10)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab-rag-e2e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
