{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a80179e",
   "metadata": {},
   "source": [
    "# Router\n",
    "\n",
    "Routing the message can provide several strategies to optmice your LLM.  \n",
    "\n",
    "In a RAG App, does every message need to be directed to a retrieval? OF course not.\n",
    "So the first goal is to differenciate `intents` in treat them propperly.\n",
    "\n",
    "Intents are a classic strategy in chatbot development before the introduction of LLMs (<2023)\n",
    "* Few shot learning fast classifiers where used\n",
    "\n",
    "\n",
    "We can approach this task with two approaches:\n",
    "* Semantic Routing: Comparing user messages to a set of predefined intents, using embeddings\n",
    "* LLM Based routing: Intruct a LLM with structured outputs and then use the LLM to route messages based on\n",
    "\n",
    "In both cases, a graph workflow will come handy :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048ab727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bba54eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from src import utils, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10d594",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8eb5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_settings = conf.load(file=\"settings.yaml\")\n",
    "conf_infra = conf.load(file=\"infra.yaml\")    \n",
    "\n",
    "LLM_WORKHORSE = conf_settings.llm_workhorse\n",
    "LLM_FLAGSHIP = conf_settings.llm_flagship\n",
    "EMBEDDINGS = conf_settings.embeddings\n",
    "VDB_URL = conf_infra.vdb_url\n",
    "INDEX_NAME = conf_settings.vdb_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2cf4c6",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d76475a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077a74e",
   "metadata": {},
   "source": [
    "# Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92ad2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:22:40 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "C:\\Users\\manuelalberto.romero\\AppData\\Local\\Temp\\ipykernel_49752\\4146529736.py:6: RuntimeWarning: coroutine 'VectorStore.asimilarity_search' was never awaited\n",
      "  _ = llm.invoke(\"tell me a joke about devops\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2025-09-11 23:22:41 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 23:22:56 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: GET https://e0634f57-b3c9-4193-8355-cf7e48c8e247.europe-west3-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 23:22:57 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: GET https://e0634f57-b3c9-4193-8355-cf7e48c8e247.europe-west3-0.gcp.cloud.qdrant.io:6333/collections/space \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 23:22:57 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=LLM_WORKHORSE,\n",
    "    )\n",
    "try:\n",
    "    _ = llm.invoke(\"tell me a joke about devops\")\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    \n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=EMBEDDINGS)\n",
    "try:\n",
    "    _ = embeddings.embed_query(\"healthcheck\")\n",
    "\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name=INDEX_NAME,\n",
    "    url=VDB_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "try:\n",
    "    _ = vector_store.asimilarity_search(\"healthcheck\")\n",
    "except Exception as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00a8bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=LLM_WORKHORSE,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e968c21",
   "metadata": {},
   "source": [
    "# Context Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ba891d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"John J. Hopfield and Geoffrey Hinton received the Nobel Prize in Physics in 2024 for their groundbreaking work on artificial neural networks, a foundation of modern AI. Hopfield developed an associative memory model in the 1980s that allows networks to store and reconstruct patterns. Building on this, Hinton developed the Boltzmann machine, which uses statistical physics principles to recognize and classify data. These pioneering contributions are essential for today's machine learning technologies, enhancing applications from medical imaging to material science.\",\n",
    "        metadata={\"source\": \"wikipedia\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"In Chemistry, David Baker, Demis Hassabis, and John Jumper were honored win Nobel Prize in 2024 for their breakthroughs in protein structure prediction. Baker’s work in computational protein design enables the creation of novel proteins, while Hassabis and Jumper, known for their work with DeepMind's AlphaFold, developed an AI that accurately predicts protein structures—a long-standing challenge in biology. This advancement could lead to transformative applications in drug development and synthetic biology.\",\n",
    "        metadata={\"source\": \"wikipedia\"}\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36552259",
   "metadata": {},
   "source": [
    "# Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d6caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c251434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:22:58 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Router(route=<Intents.SCIENCE: 'science'>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Intents(Enum):\n",
    "    \"\"\"Available intents for the applications\"\"\"\n",
    "    SCIENCE = \"science\"\n",
    "    POLITICS = \"politics\"\n",
    "    GUARDRAILS = \"guardrails\"\n",
    "    CHAT = \"chat\"\n",
    "\n",
    "class Router(BaseModel):\n",
    "    \"\"\"\n",
    "    Classify user message in the given set of routes.\n",
    "    \"\"\"\n",
    "    route: Intents  = Field(..., description=\"Intent classification in a given set of topics\")\n",
    "\n",
    "\n",
    "router_template = \"\"\"Given a user message, classify in a predefined set of topics\n",
    "User message: {question}\n",
    "\"\"\"\n",
    "\n",
    "llm_router = llm.with_structured_output(Router)\n",
    "prompt_router = ChatPromptTemplate.from_template(router_template)\n",
    "chain_router = prompt_router | llm_router\n",
    "\n",
    "chain_router.invoke(\n",
    "    {\n",
    "        \"question\": \"How won the Physics Nobel price in 2024?\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8970d",
   "metadata": {},
   "source": [
    "## Test your chain: Pytest in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a20e2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4eec0eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:00 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      ".venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      ".venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; langsmith\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 0.48s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest --capture=no\n",
    "\n",
    "def test_router_example():\n",
    "\n",
    "    question = \"How won the Physics Nobel price in 2024?\"\n",
    "    expected = Intents.SCIENCE\n",
    "    res = chain_router.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    assert isinstance(res, Router), \"Output is not a Router\"\n",
    "    assert res.route == expected, \"Routes does not match\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09a92347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:02 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:03 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:03 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:04 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      ".venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      ".venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  c:\\Users\\manuelalberto.romero\\Documents\\repos\\dslabs\\dslab-rag-e2e\\.venv\\lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; langsmith\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m4 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 2.52s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest --capture=no\n",
    "\n",
    "@pytest.mark.parametrize( \n",
    "  \"question, expected\",[\n",
    "      (\"Tell me a joke about AI\", Intents.CHAT),\n",
    "      (\"How won the Physics Nobel price in 2024?\", Intents.SCIENCE),\n",
    "      (\"What happened after President Kennedy assessination\", Intents.POLITICS),\n",
    "      (\"Tell me how to craft a bomb\", Intents.GUARDRAILS)\n",
    "      ],\n",
    ")\n",
    "def test_router(question: str, expected: Intents):\n",
    "\n",
    "    res = chain_router.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    assert isinstance(res, Router), \"Output is not a Router\"\n",
    "    assert res.route == expected, \"Routes does not match\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310b69a",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94da8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    intent: Intents\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "def retrieve(state: State):\n",
    "    print(\"----- RETRIEVE -----\")\n",
    "    # Could dinamic index selection be implemented here? :)\n",
    "    return {\"context\": docs}\n",
    "\n",
    "def router(state: State) -> Intents:\n",
    "    print(\"----- ROUTER -----\")\n",
    "    question = state['question']\n",
    "\n",
    "    resp = chain_router.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "        }\n",
    "    )\n",
    "    intent = resp.route  # Intents\n",
    "    return intent    \n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "    ```\n",
    "    {context}\n",
    "    ```\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"----- GENERATE -----\")\n",
    "    docs_content = format_docs(state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"answer\": response.content,\n",
    "        \"intent\": \"SCIENCE|POLITICS\"\n",
    "        }\n",
    "\n",
    "def chichat(state: State):\n",
    "    print(\"----- CHITCHAT -----\")\n",
    "    question = state['question']\n",
    "    resp = llm.invoke(question)\n",
    "    return {\n",
    "        \"answer\": resp.content,\n",
    "        \"intent\": \"CHAT\"\n",
    "        }\n",
    "\n",
    "\n",
    "def guardrails(state: State):\n",
    "    print(\"----- GUARDRAILS -----\")\n",
    "    return {\n",
    "        \"answer\": \"Sorry,  I cannot provide any information about this topic.\",\n",
    "        \"intent\": \"GUARDRAILS\"\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "g = StateGraph(State)\n",
    "g.add_node(\"router\", router)\n",
    "g.add_node(\"retrieve\", retrieve)\n",
    "g.add_node(\"chichat\", chichat)\n",
    "g.add_node(\"generate\", generate)\n",
    "g.add_node(\"guardrails\", guardrails)\n",
    "\n",
    "\n",
    "branches = {\n",
    "    Intents.SCIENCE: \"retrieve\",\n",
    "    Intents.POLITICS: \"retrieve\",\n",
    "    Intents.GUARDRAILS: \"guardrails\",\n",
    "    Intents.CHAT: \"chichat\"\n",
    "}\n",
    "\n",
    "g.add_conditional_edges(START, router, branches)\n",
    "g.add_edge(\"retrieve\", \"generate\")\n",
    "g.add_edge(\"chichat\", END)\n",
    "g.add_edge(\"guardrails\", END)\n",
    "\n",
    "agent = g.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4090dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ROUTER -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:06 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- RETRIEVE -----\n",
      "----- GENERATE -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 23:23:07 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How won the Physics Nobel price in 2024?',\n",
       " 'context': [Document(metadata={'source': 'wikipedia'}, page_content=\"John J. Hopfield and Geoffrey Hinton received the Nobel Prize in Physics in 2024 for their groundbreaking work on artificial neural networks, a foundation of modern AI. Hopfield developed an associative memory model in the 1980s that allows networks to store and reconstruct patterns. Building on this, Hinton developed the Boltzmann machine, which uses statistical physics principles to recognize and classify data. These pioneering contributions are essential for today's machine learning technologies, enhancing applications from medical imaging to material science.\"),\n",
       "  Document(metadata={'source': 'wikipedia'}, page_content=\"In Chemistry, David Baker, Demis Hassabis, and John Jumper were honored win Nobel Prize in 2024 for their breakthroughs in protein structure prediction. Baker’s work in computational protein design enables the creation of novel proteins, while Hassabis and Jumper, known for their work with DeepMind's AlphaFold, developed an AI that accurately predicts protein structures—a long-standing challenge in biology. This advancement could lead to transformative applications in drug development and synthetic biology.\")],\n",
       " 'answer': 'John J. Hopfield and Geoffrey Hinton won the Nobel Prize in Physics in 2024.',\n",
       " 'intent': 'SCIENCE|POLITICS'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = agent.invoke({\"question\": \"How won the Physics Nobel price in 2024?\"})\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8acba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab-rag-e2e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
